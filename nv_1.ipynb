{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea6f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Config ---\n",
    "input_dir = 'training_input'\n",
    "output_dir = 'training_output'\n",
    "\n",
    "# heuristics and keywords for header/logo detection\n",
    "REPEAT_PAGES_THRESHOLD = 0.5  # repeated text on >=50% pages is header\n",
    "MAX_TOP_PX = 120\n",
    "TOP_FRAC = 0.12  # fraction of page height to inspect if tall\n",
    "\n",
    "def ensure_dirs(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Convert lines to Markdown with numbered headings and nested bullets.\n",
    "    \n",
    "    ĐÃ CẬP NHẬT: Tất cả các Heading được thêm \\n\\n trước và sau để tạo khoảng cách lớn.\n",
    "    \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    out = []\n",
    "\n",
    "    for raw in lines:\n",
    "        line = raw.rstrip()\n",
    "        if not line:\n",
    "            out.append('')\n",
    "            continue\n",
    "\n",
    "        # Numbered headings: 1., 1.2., 1.2.1., 1.2.1.2 etc.\n",
    "        m = re.match(r'^(\\d+(\\.\\d+)+)\\.?\\s+(.*)', line)\n",
    "        if m:\n",
    "            numbering = m.group(1)\n",
    "            content = m.group(3)\n",
    "            level = numbering.count('.')  # số dấu chấm = cấp heading\n",
    "            if level > 6:\n",
    "                level = 6\n",
    "            # THÊM KHOẢNG CÁCH LỚN TRƯỚC VÀ SAU HEADING\n",
    "            out.append(f'\\n\\n{\"#\" * level} {content}\\n\\n')\n",
    "            continue\n",
    "\n",
    "        # Bullet list\n",
    "        m2 = re.match(r'^([ \\t]*)([-•\\*\\u2022])\\s+(.*)', line)\n",
    "        if m2:\n",
    "            indent_spaces = len(m2.group(1).replace('\\t', '    '))\n",
    "            level = indent_spaces // 2\n",
    "            content = m2.group(3)\n",
    "            out.append(f'{\"  \" * level}- {content}')\n",
    "            continue\n",
    "\n",
    "        # Heading: Chương / Mục\n",
    "        if re.match(r'^(Chương|CHƯƠNG) \\d+:?', line, re.IGNORECASE):\n",
    "            title = re.split(r':', line, 1)[-1].strip()\n",
    "            # THÊM KHOẢNG CÁCH LỚN TRƯỚC VÀ SAU HEADING\n",
    "            out.append(f'\\n\\n# {title}\\n\\n')\n",
    "            continue\n",
    "\n",
    "        # Default: paragraph\n",
    "        out.append(line)\n",
    "\n",
    "    return '\\n'.join(out)\n",
    "\n",
    "ensure_dirs(output_dir)\n",
    "ensure_dirs(input_dir)\n",
    "\n",
    "for pdf_file in os.listdir(input_dir):\n",
    "    if not pdf_file.lower().endswith('.pdf'):\n",
    "        continue\n",
    "\n",
    "    pdf_path = os.path.join(input_dir, pdf_file)\n",
    "    pdf_name = os.path.splitext(pdf_file)[0]\n",
    "    out_folder = os.path.join(output_dir, pdf_name)\n",
    "    img_folder = os.path.join(out_folder, 'images')\n",
    "    ensure_dirs(out_folder)\n",
    "    ensure_dirs(img_folder)\n",
    "\n",
    "    md_lines = []\n",
    "    image_count = 1\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = [doc.load_page(i) for i in range(len(doc))]\n",
    "    num_pages = len(pages)\n",
    "\n",
    "    # --- PASS 1: detect repeated header text across pages ---\n",
    "    page_top_words = []\n",
    "    for page in pages:\n",
    "        rect = page.rect\n",
    "        page_height = rect.height\n",
    "        top_limit = min(MAX_TOP_PX, page_height * TOP_FRAC)\n",
    "        words = page.get_text('words') or []\n",
    "        top_words = []\n",
    "        for w in words:\n",
    "            if len(w) < 5:\n",
    "                continue\n",
    "            x0, y0, x1, y1, word_text = w[:5]\n",
    "            if y0 <= top_limit and word_text.strip():\n",
    "                top_words.append((word_text.strip(), y0, y1))\n",
    "        page_top_words.append(top_words)\n",
    "\n",
    "    # count repeated texts\n",
    "    text_counts = {}\n",
    "    for top_words in page_top_words:\n",
    "        uniq = set(t for t, _, _ in top_words)\n",
    "        for t in uniq:\n",
    "            text_counts[t] = text_counts.get(t, 0) + 1\n",
    "    repeated_texts = {t for t, c in text_counts.items() if c >= max(2, int(REPEAT_PAGES_THRESHOLD * num_pages))}\n",
    "\n",
    "    # map repeated texts to positions\n",
    "    repeated_positions = {}\n",
    "    for i, top_words in enumerate(page_top_words):\n",
    "        for t, top, bottom in top_words:\n",
    "            if t in repeated_texts:\n",
    "                repeated_positions.setdefault(t, []).append((top, bottom))\n",
    "    for t, lst in repeated_positions.items():\n",
    "        tops = [a for a, b in lst]\n",
    "        bottoms = [b for a, b in lst]\n",
    "        repeated_positions[t] = (min(tops), max(bottoms))\n",
    "\n",
    "    # --- PASS 2: extract text and images, skip header/logo ---\n",
    "    for page_number, page in enumerate(pages, start=1):\n",
    "        rect = page.rect\n",
    "        page_height = rect.height\n",
    "        top_words = page_top_words[page_number-1]\n",
    "\n",
    "        found = []\n",
    "        for t, top, bottom in top_words:\n",
    "            if t in repeated_positions:\n",
    "                found.append((top, bottom))\n",
    "        header_bottom = max((b for t, b in found), default=min(MAX_TOP_PX, page_height * TOP_FRAC)) + 2\n",
    "\n",
    "        # text\n",
    "        words = page.get_text('words') or []\n",
    "        body_words = [w for w in words if len(w) >= 5 and w[1] >= header_bottom]\n",
    "        body_words_sorted = sorted(body_words, key=lambda w: (round(w[1]), w[0]))\n",
    "\n",
    "        lines = []\n",
    "        cur_top = None\n",
    "        cur_line = []\n",
    "        tol = 3\n",
    "        for w in body_words_sorted:\n",
    "            x0, y0, x1, y1, word_text = w[:5]\n",
    "            if cur_top is None or abs(y0 - cur_top) <= tol:\n",
    "                cur_line.append(word_text)\n",
    "                if cur_top is None:\n",
    "                    cur_top = y0\n",
    "            else:\n",
    "                if cur_line:\n",
    "                    lines.append(' '.join(cur_line))\n",
    "                cur_line = [word_text]\n",
    "                cur_top = y0\n",
    "        if cur_line:\n",
    "            lines.append(' '.join(cur_line))\n",
    "\n",
    "        # process lines to markdown\n",
    "        for line in lines:\n",
    "            processed_chunk = process_text(line)\n",
    "            # Chỉ thêm vào nếu không phải là khoảng trắng hoàn toàn\n",
    "            if processed_chunk.strip() or ('\\n\\n' in processed_chunk): \n",
    "                 md_lines.append(processed_chunk)\n",
    "\n",
    "        # images\n",
    "        blocks = page.get_text('dict').get('blocks', [])\n",
    "        for block in blocks:\n",
    "            if block.get('type') == 1:\n",
    "                bbox = block.get('bbox', [])\n",
    "                if len(bbox) != 4:\n",
    "                    continue\n",
    "                bx0, by0, bx1, by1 = bbox\n",
    "                if by0 < header_bottom:\n",
    "                    continue\n",
    "                xref = None\n",
    "                img_info = block.get('image')\n",
    "                if isinstance(img_info, dict) and 'xref' in img_info:\n",
    "                    xref = img_info.get('xref')\n",
    "                if xref is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    img_dict = doc.extract_image(xref)\n",
    "                    img_bytes = img_dict['image']\n",
    "                    img_ext = img_dict.get('ext', 'png')\n",
    "                    img_path = os.path.join(img_folder, f'image_{image_count}.{img_ext}')\n",
    "                    with open(img_path, 'wb') as imgf:\n",
    "                        imgf.write(img_bytes)\n",
    "                    md_lines.append(f'|<image_{image_count}>|')\n",
    "                    image_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f'Warning: failed extracting image on {pdf_file} page {page_number}: {e}')\n",
    "    \n",
    "    # Sử dụng `pdf_file` (tên gốc, ví dụ: 'tai_lieu.pdf')\n",
    "    # Thêm Heading cho tên file. Ký tự \\n\\n ở đây giúp đảm bảo nó cũng cách xa nội dung đầu tiên\n",
    "    md_lines.insert(0, f'\\n\\n#  {pdf_file}\\n\\n') \n",
    "    \n",
    "    # save markdown\n",
    "    md_path = os.path.join(out_folder, 'main.md')\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        # Khi join, nếu phần tử đã có \\n\\n rồi thì chỉ cần join bằng \\n.\n",
    "        # Tuy nhiên, do đã thêm \\n\\n vào Heading, chỉ cần join bằng một \\n là đủ.\n",
    "        f.write('\\n'.join(md_lines))\n",
    "\n",
    "    doc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465155c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
